{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenando un modelo de Regresón Logística para detección de pacientes con diabetes utilizando Apache Spark (PySpark) en Kaggle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalando bibliotecas necesarias con las dependencias correctas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export version=`python --version |awk '{print $2}' |awk -F\".\" '{print $1$2}'`\n",
    "\n",
    "echo $version\n",
    "\n",
    "if [ $version == '36' ] || [ $version == '37' ]; then\n",
    "    echo 'Starting installation...'\n",
    "    pip3 install pyspark==2.4.8 wget==3.2 pyspark2pmml==0.5.1 > install.log 2> install.log\n",
    "    if [ $? == 0 ]; then\n",
    "        echo 'Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)'\n",
    "    else\n",
    "        echo 'Installation failed, please check log:'\n",
    "        cat install.log\n",
    "    fi\n",
    "elif [ $version == '38' ] || [ $version == '39' ]; then\n",
    "    pip3 install pyspark==3.1.2 wget==3.2 pyspark2pmml==0.5.1 > install.log 2> install.log\n",
    "    if [ $? == 0 ]; then\n",
    "        echo 'Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)'\n",
    "    else\n",
    "        echo 'Installation failed, please check log:'\n",
    "        cat install.log\n",
    "    fi\n",
    "else\n",
    "    echo 'Currently only python 3.6, 3.7 , 3.8 and 3.9 are supported, in case you need a different version please open an issue at https://github.com/IBM/claimed/issues'\n",
    "    exit -1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando dependencias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "import os\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark2pmml import PMMLBuilder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "import logging\n",
    "import shutil\n",
    "#import sitexv\n",
    "import wget\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizando archivos en directorio de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " HMP_Dataset\t\t\t\t etl_lab.ipynb\n",
      "'Registros históricos de diabetes.csv'\t final_project.ipynb\n",
      " Untitled.ipynb\t\t\t\t install.log\n",
      " claimed\t\t\t\t'sparkml-diabetes (2).ipynb'\n",
      " claimed_1\t\t\t\t workflow.pipeline\n",
      " data\t\t\t\t\t workflow2.pipeline\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version[0:3] == '3.9':\n",
    "    url = ('https://github.com/jpmml/jpmml-sparkml/releases/download/1.7.2/'\n",
    "           'jpmml-sparkml-executable-1.7.2.jar')\n",
    "    wget.download(url)\n",
    "    shutil.copy('jpmml-sparkml-executable-1.7.2.jar',\n",
    "                site.getsitepackages()[0] + '/pyspark/jars/')\n",
    "elif sys.version[0:3] == '3.8':\n",
    "    url = ('https://github.com/jpmml/jpmml-sparkml/releases/download/1.7.2/'\n",
    "           'jpmml-sparkml-executable-1.7.2.jar')\n",
    "    wget.download(url)\n",
    "    shutil.copy('jpmml-sparkml-executable-1.7.2.jar',\n",
    "                site.getsitepackages()[0] + '/pyspark/jars/')\n",
    "elif sys.version[0:3] == '3.7':\n",
    "    url = ('https://github.com/jpmml/jpmml-sparkml/releases/download/1.5.12/'\n",
    "           'jpmml-sparkml-executable-1.5.12.jar')\n",
    "    wget.download(url)\n",
    "elif sys.version[0:3] == '3.6':\n",
    "    url = ('https://github.com/jpmml/jpmml-sparkml/releases/download/1.5.12/'\n",
    "           'jpmml-sparkml-executable-1.5.12.jar')\n",
    "    wget.download(url)\n",
    "else:\n",
    "    raise Exception('Currently only python 3.6 , 3.7, 3,8 and 3.9 is supported, in case '\n",
    "                    'you need a different version please open an issue at '\n",
    "                    'https://github.com/IBM/claimed/issues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " HMP_Dataset\t\t\t\t final_project.ipynb\n",
      "'Registros históricos de diabetes.csv'\t install.log\n",
      " Untitled.ipynb\t\t\t\t jpmml-sparkml-executable-1.5.12.jar\n",
      " claimed\t\t\t\t'sparkml-diabetes (2).ipynb'\n",
      " claimed_1\t\t\t\t workflow.pipeline\n",
      " data\t\t\t\t\t workflow2.pipeline\n",
      " etl_lab.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = os.environ.get('master',\n",
    "                        \"local[*]\")  # URL to Spark master\n",
    "model_target = os.environ.get('model_target',\n",
    "                              \"model.xml\")  # model output file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = list(\n",
    "    map(lambda s: re.sub('$', '\"', s),\n",
    "        map(\n",
    "            lambda s: s.replace('=', '=\"'),\n",
    "            filter(\n",
    "                lambda s: s.find('=') > -1 and bool(re.match(r'[A-Za-z0-9_]*=[.\\/A-Za-z0-9]*', s)),\n",
    "                sys.argv\n",
    "            )\n",
    "    )))\n",
    "\n",
    "for parameter in parameters:\n",
    "    logging.warning('Parameter: ' + parameter)\n",
    "    exec(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/23 17:51:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setMaster(master)\n",
    "conf.set(\"spark.jars\", 'jpmml-sparkml-executable-1.5.12.jar')\n",
    "\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = sqlContext.sparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creando pandas DataFrame utilizando la url original (correo de requerimientos) del archivo .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Registros históricos de diabetes.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizando los 5 primeros registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+---------------------------+---------------------------+--------------------------+------------------------+-----------+------------------------+----+-----------+\n",
      "|Paciente|Nmero de embarazos|Nivel de glucosa plasmtica|Presion arterial diastlica|Espesor de pliegue cutneo|Nivel de insulina srica|        IMC|Probabilidad de diabetes|Edad|ÀDiabtico?|\n",
      "+--------+-------------------+---------------------------+---------------------------+--------------------------+------------------------+-----------+------------------------+----+-----------+\n",
      "| 1354778|                  0|                        171|                         80|                        34|                      23|43.50972593|             1.213191354|  21|          0|\n",
      "| 1147438|                  8|                         92|                         93|                        47|                      36|21.24057571|             0.158364981|  23|          0|\n",
      "| 1640031|                  7|                        115|                         47|                        52|                      35|41.51152348|             0.079018568|  23|          0|\n",
      "| 1883350|                  9|                        103|                         78|                        25|                     304|29.58219193|             1.282869847|  43|          1|\n",
      "| 1424119|                  1|                         85|                         59|                        27|                      35|42.60453585|             0.549541871|  22|          0|\n",
      "+--------+-------------------+---------------------------+---------------------------+--------------------------+------------------------+-----------+------------------------+----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Paciente: long (nullable = true)\n",
      " |-- Nmero de embarazos: long (nullable = true)\n",
      " |-- Nivel de glucosa plasmtica: long (nullable = true)\n",
      " |-- Presion arterial diastlica: long (nullable = true)\n",
      " |-- Espesor de pliegue cutneo: long (nullable = true)\n",
      " |-- Nivel de insulina srica: long (nullable = true)\n",
      " |-- IMC: double (nullable = true)\n",
      " |-- Probabilidad de diabetes: double (nullable = true)\n",
      " |-- Edad: long (nullable = true)\n",
      " |-- ÀDiabtico?: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiando nombre de columnas para facilitar el análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"Paciente\", \"id_paciente\") \\\n",
    ".withColumnRenamed(\"Nmero de embarazos\", \"embarazos\") \\\n",
    ".withColumnRenamed(\"Nivel de glucosa plasmtica\", \"glucosa\") \\\n",
    ".withColumnRenamed(\"Presion arterial diastlica\", \"diastole\") \\\n",
    ".withColumnRenamed(\"Espesor de pliegue cutneo\", \"espesor\") \\\n",
    ".withColumnRenamed(\"Nivel de insulina srica\", \"insulina\") \\\n",
    ".withColumnRenamed(\"IMC\", \"imc\") \\\n",
    ".withColumnRenamed(\"Probabilidad de diabetes\", \"prob\") \\\n",
    ".withColumnRenamed(\"Edad\", \"edad\") \\\n",
    ".withColumnRenamed(\"ÀDiabtico?\", \"diab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_paciente: long (nullable = true)\n",
      " |-- embarazos: long (nullable = true)\n",
      " |-- glucosa: long (nullable = true)\n",
      " |-- diastole: long (nullable = true)\n",
      " |-- espesor: long (nullable = true)\n",
      " |-- insulina: long (nullable = true)\n",
      " |-- imc: double (nullable = true)\n",
      " |-- prob: double (nullable = true)\n",
      " |-- edad: long (nullable = true)\n",
      " |-- diab: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:===================================>                     (10 + 6) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "positivos = spark.sql(\"SELECT COUNT(*) as count FROM diabetes WHERE diab = 1\").first()['count'] \n",
    "print(positivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:==========>                                              (3 + 13) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "negativos = spark.sql(\"SELECT COUNT(*) as count FROM diabetes WHERE diab = 0\").first()['count'] \n",
    "print(negativos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:==========>                                              (3 + 13) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "totales = spark.sql(\"SELECT COUNT(*) as count FROM diabetes\").first()['count'] \n",
    "print(totales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de positivos 33.44\n",
      "Porcentaje de negativos 66.56\n"
     ]
    }
   ],
   "source": [
    "# Porcentaje de positivos\n",
    "print(\"Porcentaje de positivos\", str(positivos/totales*100))\n",
    "\n",
    "# Porcentaje de negativos\n",
    "print(\"Porcentaje de negativos\", str(negativos/totales*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe un desbalance de clases con una relación de 2 a 1. Para intentar resolver este problema se pueden implementar diferentes estrategias como submuestreo de clase negativa, sobremuestreo de clase positiva, remuestreo o modificar la función de costos para considerar el peso de cada clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuántos registros son únicos con respecto al ID de pacientes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9959"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(DISTINCT id_paciente) as count FROM diabetes\").first()['count'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen pacientes con múltiples registros, Estos pacientes deberían estar en el mismo conjunto (validación o entrenamiento) para no sobrestimar las métricas de rendimiento del modelo, sin embargo, al ser menos del 1% de los registros se espera que su imacto sea mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creando conjuntos de entrenamiento y validación con relación 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df.randomSplit([0.8, 0.2])\n",
    "df_train = splits[0]\n",
    "df_test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Son coherentes los datos de la columna \"Probabilidad de diabetes\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================================>       (172 + 18) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|  781|\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(DISTINCT id_paciente) as count FROM diabetes \\\n",
    "WHERE prob > 1 OR prob < 0\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en el query anterior, algunos registros no cumplen la definición de probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se definen las características que podrían ser relevantes para el modelo predictivo a optimizar. Se excluyen como entradas del modelo las columnas prob y diab por ser las variables objetivo (target). Así como la columna id_paciente por ser identificador.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = os.environ.get('input_columns',\n",
    "                               '[\"embarazos\", \\\n",
    "                               \"glucosa\", \\\n",
    "                               \"diastole\", \\\n",
    "                               \"espesor\", \\\n",
    "                               \"insulina\", \\\n",
    "                               \"imc\", \\\n",
    "                               \"edad\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"diab\", outputCol=\"label\")\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols=eval(input_columns),\n",
    "                                  outputCol=\"features\")\n",
    "\n",
    "normalizer = MinMaxScaler(inputCol=\"features\", outputCol=\"features_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=100, regParam=0.01, elasticNetParam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[indexer, vectorAssembler, normalizer, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/23 17:54:09 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/12/23 17:54:09 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones en el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones en el conjunto de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = model.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrando probabilidades de pertenencia a la clase positiva (diabético) del conjunto de entrenamiento (5 ejemplos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         probability|label|\n",
      "+--------------------+-----+\n",
      "|[0.80622990882120...|  0.0|\n",
      "|[0.87379879015652...|  0.0|\n",
      "|[0.27934286039219...|  1.0|\n",
      "|[0.69642477031099...|  0.0|\n",
      "|[0.80360131480540...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select('probability', 'label').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         probability|label|\n",
      "+--------------------+-----+\n",
      "|[0.62878499798074...|  1.0|\n",
      "|[0.20552617493825...|  1.0|\n",
      "|[0.01663430322969...|  1.0|\n",
      "|[0.94477828351039...|  0.0|\n",
      "|[0.57213990872888...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction2.select('probability', 'label').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_paciente: long (nullable = true)\n",
      " |-- embarazos: long (nullable = true)\n",
      " |-- glucosa: long (nullable = true)\n",
      " |-- diastole: long (nullable = true)\n",
      " |-- espesor: long (nullable = true)\n",
      " |-- insulina: long (nullable = true)\n",
      " |-- imc: double (nullable = true)\n",
      " |-- prob: double (nullable = true)\n",
      " |-- edad: long (nullable = true)\n",
      " |-- diab: long (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- features_norm: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', 'weightedPrecision', 'weightedRecall', 'f1','areaUnderROC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7770219198790628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedPrecision: 0.7701009472022863\n",
      "weightedRecall: 0.7770219198790627\n",
      "f1: 0.7690588694184151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.8489522850781758\n"
     ]
    }
   ],
   "source": [
    "for i in metrics:\n",
    "    if i == 'areaUnderROC':\n",
    "        binEval = BinaryClassificationEvaluator()\n",
    "        print(i+\": \"+str(binEval.evaluate(prediction)))\n",
    "    else:\n",
    "        binEval = MulticlassClassificationEvaluator(). \\\n",
    "        setMetricName(i). \\\n",
    "        setPredictionCol(\"prediction\"). \\\n",
    "        setLabelCol(\"label\")\n",
    "        print(i+\": \"+str(binEval.evaluate(prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas del conjunto de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7832201745877788\n",
      "weightedPrecision: 0.7805744057365932\n",
      "weightedRecall: 0.7832201745877789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.7750055052781868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.8552561016546716\n"
     ]
    }
   ],
   "source": [
    "for i in metrics:\n",
    "    if i == 'areaUnderROC':\n",
    "        binEval = BinaryClassificationEvaluator()\n",
    "        print(i+\": \"+str(binEval.evaluate(prediction2)))\n",
    "    else:\n",
    "        binEval = MulticlassClassificationEvaluator(). \\\n",
    "        setMetricName(i). \\\n",
    "        setPredictionCol(\"prediction\"). \\\n",
    "        setLabelCol(\"label\")\n",
    "        print(i+\": \"+str(binEval.evaluate(prediction2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia de 'accuracy' entre los dos conjuntos es apenas perceptible, lo que significa que el modelo está \"ligeramente\" subajustado. El F1 score es la media harmónica de la \"precisión de recuperación de información\" (probabilidad de hallar a un enfermo si la prueba es positiva) y sensibilidad (probabilidad de que la prueba sea positiva si el individuo está enfermo), siendo una métrica utilizada para conocer que tan buena es la prueba para encontrar positivos. Así mismo la AUC proporciona información sobre la eficiencia del modelo para diferentes umbrales de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando modelo final en pmml para despliegue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/resources/labs/BD0231EN/model.xml'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmmlBuilder = PMMLBuilder(sc, df_train, model)\n",
    "pmmlBuilder.buildFile(model_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PMMLBuilder in module pyspark2pmml:\n",
      "\n",
      "class PMMLBuilder(builtins.object)\n",
      " |  PMMLBuilder(sc, df, pipelineModel)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sc, df, pipelineModel)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  build(self)\n",
      " |  \n",
      " |  buildByteArray(self)\n",
      " |  \n",
      " |  buildFile(self, path)\n",
      " |  \n",
      " |  putOption(self, pipelineStage, key, value)\n",
      " |  \n",
      " |  verify(self, df, precision=1e-14, zeroThreshold=1e-14)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(PMMLBuilder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
